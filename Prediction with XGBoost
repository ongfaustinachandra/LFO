# -*- coding: utf-8 -*-
"""
Created on Tue Nov  2 09:50:56 2021

@author: Faustina Chandra
"""

import numpy as np
import pandas as pd

# Generating Data
# Columns: Servicegrad, Prognosefehler, Bestellkosten, WBZ, Label
# Label consist only [0, 1]
df = pd.read_csv('Rohdaten_Gesamtkosten_RangMittelwert_LUCPP.csv', delimiter=(';'))
features, targets = [], []

for i in range(297):
    features.append([df['Servicegrad'][i], df['Prognosefehler'][i], df['Bestellkosten'][i], df['WBZ'][i]])
    targets.append(df['Label'][i])

features = np.asarray(features)
targets = np.asarray(targets)
#print(features)
#print(targets)

# ===== XGBoost for CLASSIFICATION =====
print('=== XGBosot for Classification ===')
from numpy import asarray
from numpy import mean
from numpy import std
#from sklearn.datasets import make_classification
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from matplotlib import pyplot
# define dataset
#X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)
# evaluate the model
model = XGBClassifier(use_label_encoder=False, eval_metric='error')
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
n_scores = cross_val_score(model, features, targets, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
print('Accuracy: %.3f (%.3f)' % (mean(n_scores)*100, std(n_scores)*100))
# fit the model on the whole dataset
model = XGBClassifier(use_label_encoder=False, eval_metric='error')
model.fit(features, targets)
# make a single prediction
#row = [2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]
row = [4, 1, 40, 7]
row = asarray(row).reshape((1, len(row)))
yhat = model.predict(row)
print('Prediction: %d' % yhat[0])


# XGBoost for REGRESSION
print('=== XGBoost for Regression ===')
from numpy import asarray
from numpy import mean
from numpy import std
from sklearn.datasets import make_regression
from xgboost import XGBRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from matplotlib import pyplot
# define dataset
#X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)
# evaluate the model
model = XGBRegressor(objective='reg:squarederror')
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
n_scores = cross_val_score(model, features, targets, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')
print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))
# fit the model on the whole dataset
model = XGBRegressor(objective='reg:squarederror')
model.fit(features, targets)
# make a single prediction
row = [4, 1, 40, 7]
row = asarray(row).reshape((1, len(row)))
yhat = model.predict(row)
print('Prediction: %.3f' % yhat[0])
